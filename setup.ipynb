{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Set up the transforms for the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the data to have zero mean and unit variance\n",
    "])\n",
    "\n",
    "# Load the training and test datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders for the training and test sets\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# Set the path to the directory containing the CIFAR10 dataset\n",
    "data_dir = './data/cifar-10-batches-py/'\n",
    "\n",
    "# Load the training data\n",
    "train_data = None\n",
    "train_labels = []\n",
    "\n",
    "for batch in range(1, 6):\n",
    "    file = data_dir + 'data_batch_' + str(batch)\n",
    "    batch_data = unpickle(file)\n",
    "    if train_data is None:\n",
    "        train_data = batch_data[b'data']\n",
    "    else:\n",
    "        train_data = np.vstack((train_data, batch_data[b'data']))\n",
    "    train_labels += batch_data[b'labels']\n",
    "\n",
    "# Load the test data\n",
    "test_data = None\n",
    "test_labels = []\n",
    "\n",
    "file = data_dir + 'test_batch'\n",
    "test_batch = unpickle(file)\n",
    "test_data = test_batch[b'data']\n",
    "test_labels = test_batch[b'labels']\n",
    "\n",
    "# Convert the data to the format expected by PyTorch\n",
    "train_data = train_data.reshape((50000, 3, 32, 32))\n",
    "train_data = np.transpose(train_data, (0, 2, 3, 1))\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "test_data = test_data.reshape((10000, 3, 32, 32))\n",
    "test_data = np.transpose(test_data, (0, 2, 3, 1))\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class_names = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}\n",
    "\n",
    "# Get the first image and label from the training set\n",
    "image, label = trainset[0]\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "image = np.transpose(image, (1, 2, 0))\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "# Print the class name\n",
    "class_name = class_names[label]\n",
    "print(class_name)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
